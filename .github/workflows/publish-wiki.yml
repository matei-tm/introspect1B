name: 5. Publish Wiki

on:
  workflow_dispatch:
    # Allow manual triggering
  schedule:
    # Run daily at 2:00 AM GMT
    - cron: '0 2 * * *'

jobs:
  publish-wiki:
    name: Clone and Publish Wiki
    runs-on: ubuntu-latest
    permissions:
      contents: write      # Required for creating releases and pushing tags
      id-token: write      # Required for OIDC authentication
      packages: write      # Required for GitHub Packages (if needed)
    
    steps:
      - name: Checkout main repository
        uses: actions/checkout@v4
        with:
          path: main-repo

      - name: Clone wiki repository
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ðŸ“š Cloning wiki repository..."
          git clone https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.wiki.git wiki-repo || {
            echo "âš ï¸ Wiki repository not found or not initialized"
            echo "To initialize the wiki, visit: https://github.com/${{ github.repository }}/wiki"
            exit 1
          }

      - name: List wiki pages
        run: |
          echo "ðŸ“‹ Wiki pages found:"
          cd wiki-repo
          find . -name "*.md" -type f | sort
          echo ""
          echo "ðŸ“Š Total pages: $(find . -name "*.md" -type f | wc -l)"

      - name: Install dependencies
        run: |
          echo "ðŸ“¦ Installing dependencies..."
          sudo apt-get update
          sudo apt-get install -y pandoc texlive-xetex texlive-fonts-recommended texlive-plain-generic texlive-lang-chinese fonts-noto-color-emoji fonts-noto fonts-dejavu chromium-browser
          
          # Install Node.js for Mermaid CLI
          curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
          sudo apt-get install -y nodejs
          
          # Install mermaid-cli for diagram conversion
          sudo npm install -g @mermaid-js/mermaid-cli
          
          # Install Puppeteer with Chrome
          sudo npm install -g puppeteer
          
          # Install Chrome for Puppeteer (required by mermaid-cli)
          npx puppeteer browsers install chrome || echo "âš ï¸ Puppeteer Chrome install failed, will use system Chromium"

      - name: Convert wiki to PDF
        run: |
          cd wiki-repo
          echo "ðŸ”„ Preparing wiki for PDF conversion..."
          
          # Create output directory
          mkdir -p pdf-output
          mkdir -p images
          
          # Copy existing images from docs/media if it exists
          if [ -d "docs/media" ]; then
            echo "ðŸ“ Copying images from docs/media..."
            cp -r docs/media/* images/ 2>/dev/null || echo "No files in docs/media to copy"
            ls -la images/
          fi
          
          # Download all referenced images from URLs (external images)
          echo "ðŸ“¥ Downloading external images from URLs..."
          find . -name "*.md" -type f | while read file; do
            # Extract image URLs (both ![alt](url) and <img src="url">)
            grep -oE '!\[.*\]\((https?://[^)]+)\)' "$file" | sed -E 's/!\[.*\]\(([^)]+)\)/\1/' | while read url; do
              filename=$(basename "$url" | sed 's/[?#].*//')
              echo "Downloading: $url -> images/$filename"
              curl -sL "$url" -o "images/$filename" 2>&1 || echo "Failed to download $url"
            done
            
            grep -oE '<img[^>]+src="(https?://[^"]+)"' "$file" | sed -E 's/.*src="([^"]+)".*/\1/' | while read url; do
              filename=$(basename "$url" | sed 's/[?#].*//')
              echo "Downloading: $url -> images/$filename"
              curl -sL "$url" -o "images/$filename" 2>&1 || echo "Failed to download $url"
            done
          done
          
          # Replace various image path formats with local paths
          echo "ðŸ”„ Updating image references to local paths..."
          find . -name "*.md" -type f | while read file; do
            # Replace docs/media/ paths with images/
            sed -i.bak -E 's|!\[([^]]*)\]\(docs/media/([^)]+)\)|![\1](images/\2)|g' "$file"
            sed -i.bak -E 's|<img([^>]*)src="docs/media/([^"]+)"([^>]*)>|<img\1src="images/\2"\3>|g' "$file"
            
            # Replace /docs/media/ paths with images/
            sed -i.bak -E 's|!\[([^]]*)\]\(/docs/media/([^)]+)\)|![\1](images/\2)|g' "$file"
            sed -i.bak -E 's|<img([^>]*)src="/docs/media/([^"]+)"([^>]*)>|<img\1src="images/\2"\3>|g' "$file"
            
            # Replace URL image references with local paths
            sed -i.bak -E 's|!\[([^]]*)\]\((https?://[^)]+/([^/)]+))\)|![\1](images/\3)|g' "$file"
            sed -i.bak -E 's|<img([^>]*)src="https?://[^"/]+/([^"]+)"([^>]*)>|<img\1src="images/\2"\3>|g' "$file"
            
            rm -f "${file}.bak"
          done
          
          # Process Mermaid diagrams
          echo "ðŸŽ¨ Converting Mermaid diagrams to images..."
          
          # Configure Puppeteer for mermaid-cli
          cat > /tmp/puppeteer-config.json << 'PUPCONFIG'
          {
            "args": ["--no-sandbox", "--disable-setuid-sandbox"]
          }
          PUPCONFIG
          
          # First, extract all mermaid blocks to separate files
          counter=1
          for file in $(find . -name "*.md" -type f | sort); do
            if grep -q '```mermaid' "$file"; then
              echo "Processing Mermaid diagrams in $file"
              
              # Extract mermaid blocks using awk
              awk '
                /```mermaid/ { in_mermaid=1; block=""; next }
                /```/ && in_mermaid { 
                  if (block != "") {
                    print block > "/tmp/mermaid_" counter ".mmd"
                    counter++
                  }
                  in_mermaid=0
                  block=""
                  next
                }
                in_mermaid { block = block $0 "\n" }
              ' counter=$counter "$file"
              
              # Update counter based on how many blocks were found
              new_counter=$(find /tmp -name "mermaid_*.mmd" 2>/dev/null | wc -l)
              counter=$((new_counter + 1))
            fi
          done
          
          # Convert all extracted mermaid files to PNG
          echo "ðŸ” Locating Chrome browser for Mermaid rendering..."
          
          # Find Chrome executable installed by Puppeteer
          CHROME_PATH=$(find ~/.cache/puppeteer/chrome -name chrome -type f 2>/dev/null | head -1)
          if [ -z "$CHROME_PATH" ]; then
            echo "Chrome not found in Puppeteer cache, trying system paths..."
            CHROME_PATH=$(which google-chrome || which chromium || which chromium-browser || echo "/usr/bin/chromium-browser")
          fi
          
          if [ -n "$CHROME_PATH" ] && [ -f "$CHROME_PATH" ]; then
            echo "âœ“ Using Chrome at: $CHROME_PATH"
            export PUPPETEER_EXECUTABLE_PATH="$CHROME_PATH"
          else
            echo "âš ï¸ Warning: Chrome not found, Mermaid conversion may fail"
          fi
          
          for mmd_file in /tmp/mermaid_*.mmd; do
            if [ -f "$mmd_file" ]; then
              base=$(basename "$mmd_file" .mmd)
              echo "Converting $base to PNG..."
              mmdc -i "$mmd_file" -o "images/${base}.png" -b transparent -p /tmp/puppeteer-config.json || echo "Failed to convert $base"
            fi
          done
          
          # Replace mermaid blocks with image references
          echo "ðŸ”„ Replacing Mermaid blocks with images..."
          counter=1
          for file in $(find . -name "*.md" -type f | sort); do
            if grep -q '```mermaid' "$file"; then
              # Replace each mermaid block with image reference
              awk -v start_counter=$counter '
                BEGIN { counter = start_counter }
                /```mermaid/ { 
                  in_mermaid=1
                  img_path = "images/mermaid_" counter ".png"
                  print "\n![Mermaid Diagram](" img_path ")\n"
                  counter++
                  next
                }
                /```/ && in_mermaid { 
                  in_mermaid=0
                  next
                }
                !in_mermaid { print }
              ' "$file" > "${file}.tmp"
              mv "${file}.tmp" "$file"
              
              # Update global counter
              mermaid_count=$(grep -c '```mermaid' "${file}.tmp.bak" 2>/dev/null || echo "0")
              counter=$((counter + mermaid_count))
            fi
          done
          
          echo "ðŸ“š Creating combined PDF..."
          
          # Combine all markdown files into one
          echo "# Wiki Documentation" > combined.md
          echo "" >> combined.md
          echo "**Generated:** $(date +'%Y-%m-%d %H:%M:%S UTC')" >> combined.md
          echo "" >> combined.md
          echo "**Repository:** ${{ github.repository }}" >> combined.md
          echo "" >> combined.md
          echo "---" >> combined.md
          echo "" >> combined.md
          
          # Append all markdown files
          find . -name "*.md" -type f ! -name "combined.md" | sort | while read file; do
            filename=$(basename "$file" .md)
            echo "" >> combined.md
            echo "\\newpage" >> combined.md
            echo "" >> combined.md
            echo "# ${filename}" >> combined.md
            echo "" >> combined.md
            cat "$file" >> combined.md
            echo "" >> combined.md
          done
          
          # List downloaded images for debugging
          echo "ðŸ“¸ Images available for PDF:"
          ls -lh images/ || echo "No images directory"
          
          # Convert combined markdown to PDF with image support
          echo "ðŸ“„ Converting to PDF..."
          
          # Remove emojis from markdown for cleaner PDF (LaTeX has issues with emoji fonts)
          echo "ðŸ§¹ Removing emojis for PDF compatibility..."
          sed -i 's/[ðŸš€ðŸ”§ðŸ“¦ðŸ“šðŸ’°ðŸ—âœ…âŒâš ï¸ðŸ“‹ðŸ“ŠðŸ”ðŸŽ¨ðŸ”„ðŸ“¸ðŸ“„ðŸ–¼ï¸ðŸ”‘ðŸ“ðŸ”ðŸŽ¯ðŸ’»ðŸ›ðŸ“ˆðŸ“‰ðŸ“±ðŸŽšðŸŽ›ðŸ”´ðŸ”µðŸŸ¡ðŸŸ¢ðŸŸ ðŸ†˜ðŸ§¹ðŸ”—ðŸ“ðŸ¤ðŸ‘‚â±âƒ£âœ“]//g' combined.md
          
          pandoc combined.md \
            -o "pdf-output/wiki-complete.pdf" \
            --pdf-engine=xelatex \
            --toc \
            --toc-depth=2 \
            -V geometry:margin=1in \
            -V linkcolor:blue \
            -V documentclass=report \
            --resource-path=.:images \
            --standalone \
            2>&1 | head -50
          
          echo ""
          echo "âœ… PDF conversion complete"
          ls -lh pdf-output/wiki-complete.pdf

      - name: Create wiki archive
        run: |
          cd wiki-repo
          echo "ðŸ“¦ Creating archive summary..."
          
          # Create a summary file in PDF output
          cat > pdf-output/README.md << EOF
          # Wiki Documentation Archive
          
          **Generated:** $(date +'%Y-%m-%d %H:%M:%S UTC')
          **Repository:** ${{ github.repository }}
          **Branch:** ${{ github.ref_name }}
          
          ## Contents
          
          - \`wiki-complete.pdf\` - Complete wiki documentation with table of contents
          
          ## Source Pages
          
          EOF
          
          # List all source markdown files
          find . -name "*.md" -type f ! -name "combined.md" | sort | while read file; do
            echo "- \`${file#./}\`" >> pdf-output/README.md
          done
          
          echo "" >> pdf-output/README.md
          echo "---" >> pdf-output/README.md
          echo "" >> pdf-output/README.md
          echo "Total source pages: $(find . -name "*.md" -type f ! -name "combined.md" | wc -l)" >> pdf-output/README.md

      - name: Upload wiki PDF artifact
        uses: actions/upload-artifact@v4
        with:
          name: wiki-documentation-${{ github.run_number }}
          path: wiki-repo/pdf-output/wiki-complete.pdf
          retention-days: 90
          if-no-files-found: error

      - name: Create release tag
        id: create_tag
        run: |
          TAG_NAME="wiki-$(date +'%Y.%m.%d-%H%M')"
          CURRENT_DATE="$(date +'%Y-%m-%d %H:%M:%S UTC')"
          echo "tag_name=$TAG_NAME" >> $GITHUB_OUTPUT
          echo "current_date=$CURRENT_DATE" >> $GITHUB_OUTPUT
          echo "ðŸ“Œ Release tag: $TAG_NAME"

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ steps.create_tag.outputs.tag_name }}
          name: Wiki Documentation ${{ steps.create_tag.outputs.tag_name }}
          body: |
            # Wiki Documentation
            
            **Generated:** ${{ steps.create_tag.outputs.current_date }}
            **Repository:** ${{ github.repository }}
            
            This release contains the complete wiki documentation in PDF format.
            
            ## ðŸ“„ Contents
            
            - `wiki-complete.pdf` - All wiki pages with table of contents
            
            ## ðŸ“Š Features
            
            - âœ… Table of contents
            - âœ… All wiki pages combined
            - âœ… Clickable hyperlinks
            - âœ… Images and Mermaid diagrams
            - âœ… Professional formatting
            
            ## ðŸ”— Download
            
            Download the PDF from the assets below.
          draft: false
          prerelease: false
          files: |
            wiki-repo/pdf-output/wiki-complete.pdf

      - name: Create GitHub Step Summary
        run: |
          cd wiki-repo
          echo "# ðŸ“š Wiki Documentation Published" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Successfully converted wiki to PDF and published as release" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“Š Statistics" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Source Pages:** $(find . -name "*.md" -type f ! -name "combined.md" | wc -l)" >> $GITHUB_STEP_SUMMARY
          echo "- **PDF File:** \`wiki-complete.pdf\`" >> $GITHUB_STEP_SUMMARY
          echo "- **File Size:** $(ls -lh pdf-output/wiki-complete.pdf | awk '{print $5}')" >> $GITHUB_STEP_SUMMARY
          echo "- **Release Tag:** \`${{ steps.create_tag.outputs.tag_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Artifact:** \`wiki-documentation-${{ github.run_number }}\` (90 days)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“„ Document Features" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Table of contents" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… All wiki pages in one document" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Clickable hyperlinks" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Professional formatting" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… Images and Mermaid diagrams" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ”— Access" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Release:** [View Release](https://github.com/${{ github.repository }}/releases/tag/${{ steps.create_tag.outputs.tag_name }})" >> $GITHUB_STEP_SUMMARY
          echo "- **Direct Download:** [wiki-complete.pdf](https://github.com/${{ github.repository }}/releases/download/${{ steps.create_tag.outputs.tag_name }}/wiki-complete.pdf)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ’¡ **Tip:** The PDF is permanently available via GitHub Releases and temporarily as a workflow artifact." >> $GITHUB_STEP_SUMMARY
